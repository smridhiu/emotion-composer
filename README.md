
# üéµ Emotion Composer

**Emotion Composer** is an AI-powered application that captures a user's facial emotion and generates custom music, a narrated story, and a visual waveform based on the detected emotion. It's an interactive creative experience using state-of-the-art models in computer vision, language generation, and audio synthesis.

---

## üß† What It Does

1. **Emotion Detection** ‚Äì Captures an image (via webcam or upload) and detects the user's facial emotion using a Hugging Face model.
2. **Music Generation** ‚Äì Generates a custom melody reflecting the user's emotional state.
3. **Story Creation** ‚Äì Crafts a personalized short story based on the detected emotion using GPT-2.
4. **Text-to-Speech** ‚Äì Narrates the generated story using Google's TTS.
5. **Visualization** ‚Äì Displays a real-time waveform or abstract visualization matching the mood of the emotion.

---

## üõ†Ô∏è AI Tools and Models Used

| Feature               | AI Tool / Model                                             |
|----------------------|-------------------------------------------------------------|
| Emotion Detection     | `dima806/facial_emotions_image_detection` (Hugging Face)   |
| Story Generation      | `gpt2` (Hugging Face)                                       |
| Text-to-Speech (TTS)  | `gTTS` (Google Text-to-Speech)                              |
| Visualization         | `matplotlib` + `NumPy` waveform plotting                    |

---

## üöÄ How to Run the Project

### üîÅ Option 1: Run Locally with Python

1. **Clone the repository**:
   ```bash
   git clone https://github.com/your-username/emotion-composer.git
   cd emotion-composer
